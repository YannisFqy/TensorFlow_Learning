{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0Testing Accuracy0.8317\n",
      "Iter1Testing Accuracy0.8713\n",
      "Iter2Testing Accuracy0.8808\n",
      "Iter3Testing Accuracy0.8888\n",
      "Iter4Testing Accuracy0.894\n",
      "Iter5Testing Accuracy0.8963\n",
      "Iter6Testing Accuracy0.9002\n",
      "Iter7Testing Accuracy0.9027\n",
      "Iter8Testing Accuracy0.9034\n",
      "Iter9Testing Accuracy0.9052\n",
      "Iter10Testing Accuracy0.9054\n",
      "Iter11Testing Accuracy0.907\n",
      "Iter12Testing Accuracy0.9081\n",
      "Iter13Testing Accuracy0.9088\n",
      "Iter14Testing Accuracy0.9107\n",
      "Iter15Testing Accuracy0.9103\n",
      "Iter16Testing Accuracy0.9118\n",
      "Iter17Testing Accuracy0.9121\n",
      "Iter18Testing Accuracy0.9136\n",
      "Iter19Testing Accuracy0.9131\n",
      "Iter20Testing Accuracy0.9145\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True) #把MNIST_data存在文件当前目录下，否者写明绝对路径\n",
    "\n",
    "#每个批次的大小，训练模型时以批次为单位放入图片\n",
    "batch_size = 100 #每次训练放入100张图片\n",
    "#计算一共多少批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # // 代表整除\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784]) #None在执行时是100，784是因为每张图片被转换成1 * 784的向量\n",
    "y = tf.placeholder(tf.float32,[None,10]) #y是标签，数字是0-9\n",
    "\n",
    "#创建一个简单的神经网络,只有输入层和输出层\n",
    "W = tf.Variable(tf.zeros([784,10])) #每张图片有784个像素点，输入到神经网络中是一张一张输入的\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "#二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "#使用梯度下降\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #比较两个参数是否相等，返回boolean型，argmax可以返回最大的数值在第几个位置，1表示按行查找\n",
    "#argmax返回一维张量中最大的值所在的位置 https://blog.csdn.net/u013580539/article/details/79339250\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) #把boolean型转换成float型，并求平均值\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):   #把所有的图片训练21次\n",
    "         for batch in range(n_batch):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(batch_size) #图片的数据保存在batch_xs, 图片的标签保存在batch_ys，自动获取下一批次\n",
    "                sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "                \n",
    "         acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "         print(\"Iter\" + str(epoch) + \"Testing Accuracy\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0Testing Accuracy0.9112\n",
      "Iter1Testing Accuracy0.9156\n",
      "Iter2Testing Accuracy0.9179\n",
      "Iter3Testing Accuracy0.9217\n",
      "Iter4Testing Accuracy0.9195\n",
      "Iter5Testing Accuracy0.9202\n",
      "Iter6Testing Accuracy0.922\n",
      "Iter7Testing Accuracy0.9234\n",
      "Iter8Testing Accuracy0.9227\n",
      "Iter9Testing Accuracy0.9232\n",
      "Iter10Testing Accuracy0.9215\n",
      "Iter11Testing Accuracy0.9226\n",
      "Iter12Testing Accuracy0.924\n",
      "Iter13Testing Accuracy0.9229\n",
      "Iter14Testing Accuracy0.923\n",
      "Iter15Testing Accuracy0.9222\n",
      "Iter16Testing Accuracy0.9255\n",
      "Iter17Testing Accuracy0.9246\n",
      "Iter18Testing Accuracy0.9244\n",
      "Iter19Testing Accuracy0.9248\n",
      "Iter20Testing Accuracy0.9261\n"
     ]
    }
   ],
   "source": [
    "#交叉熵在调整权值或偏度值时的策略比较合理，训练模型收敛的速度会比较快\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True) #把MNIST_data存在文件当前目录下，否者写明绝对路径\n",
    "\n",
    "#每个批次的大小，训练模型时以批次为单位放入图片\n",
    "batch_size = 100 #每次训练放入100张图片\n",
    "#计算一共多少批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # // 代表整除\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784]) #None在执行时是100，784是因为每张图片被转换成1 * 784的向量\n",
    "y = tf.placeholder(tf.float32,[None,10]) #y是标签，数字是0-9\n",
    "\n",
    "#创建一个简单的神经网络,只有输入层和输出层\n",
    "W = tf.Variable(tf.zeros([784,10])) #每张图片有784个像素点，输入到神经网络中是一张一张输入的\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "Wx_plus_b_L = tf.matmul(x,W) + b\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "#交叉熵代价函数\n",
    "#loss = tf.reduce_mean(tf.square(y - prediction))    ctrl+?可以注释\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=Wx_plus_b_L))\n",
    "#使用梯度下降\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #比较两个参数是否相等，返回boolean型，argmax可以返回最大的数值在第几个位置，1表示按行查找\n",
    "#argmax返回一维张量中最大的值所在的位置 https://blog.csdn.net/u013580539/article/details/79339250\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) #把boolean型转换成float型，并求平均值\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):   #把所有的图片训练21次\n",
    "         for batch in range(n_batch):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(batch_size) #图片的数据保存在batch_xs, 图片的标签保存在batch_ys，自动获取下一批次\n",
    "                sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "                \n",
    "         acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "         print(\"Iter\" + str(epoch) + \"Testing Accuracy\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【TensorFlow】tf.nn.softmax_cross_entropy_with_logits的用法\n",
    "#https://blog.csdn.net/mao_xiao_feng/article/details/53382790\n",
    "#Tensorflow四种交叉熵函数计算公式：tf.nn.cross_entropy\n",
    "#https://blog.csdn.net/QW_sunny/article/details/72885403\n",
    "#tf.nn.softmax_cross_entropy_with_logits中的“logits”到底是个什么意思？\n",
    "#https://blog.csdn.net/yhily2008/article/details/80262321"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
